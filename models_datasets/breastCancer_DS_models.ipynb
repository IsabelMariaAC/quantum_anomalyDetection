{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Model and performance\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the necessary libraries.\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#!pip install pyod            # normal install\n",
    "#!pip install --upgrade pyod  # or update if needed\n",
    "from pyod.models.pca import PCA as PCA_PYOD\n",
    "from pyod.models.kpca import KPCA as KPCA_PYOD\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []\n",
    "dimensionality = []\n",
    "dataset = []\n",
    "\n",
    "df = load_breast_cancer()\n",
    "name = 'breast_cancer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = name+\"_data\"\n",
    "\n",
    "var = pd.DataFrame(data=df, columns=df.feature_names)\n",
    "var.columns = ['feature{}'.format(i) for i in range(0,var.shape[1])]\n",
    "\n",
    "dataset = pd.DataFrame(df.data).assign(target=df.target)\n",
    "print (dataset.shape,pd.DataFrame(df.target).nunique().tolist()[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reduced = dataset.drop(dataset[dataset['target'] == 0].sample(frac=0.20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(dataset_reduced['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(8,6)})\n",
    "g1 = sns.countplot(x=\"target\",data= dataset_reduced, palette=\"hls\")                  \n",
    "g1.set_title(\"Target variable(vowel1) Distribution\", fontsize=15)\n",
    "g1.set_xlabel(\"Vowel1\")\n",
    "g1.set_xlabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "box = sns.boxplot(data=dataset_reduced) \n",
    "box.set_xticklabels(box.get_xticklabels(), rotation= 45) \n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = Counter(dataset_reduced['target'])[0]\n",
    "inliers = Counter(dataset_reduced['target'])[1]\n",
    "\n",
    "contamination = outliers/inliers \n",
    "contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reduced[dataset_reduced.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = dataset_reduced.shape[1]     # number of features\n",
    "\n",
    "X = dataset_reduced[dataset_reduced.columns[:-1]]\n",
    "y = dataset_reduced['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "X_train_pd.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation PCA\n",
    "pca = PCA_PYOD(n_components=2, contamination=contamination) \n",
    "pca.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "y_train_pred_pca = pca.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores_pca = pca.decision_scores_  # .decision_scores_ yields the raw outlier scores for the training data\n",
    "\n",
    "# get the prediction labels and outlier scores of the test data\n",
    "y_test_scores_pca = pca.decision_function(X_test)\n",
    "y_test_pred_pca = pca.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pca.explained_variance_,\n",
    "pca.explained_variance_ratio_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction on the test data\n",
    "y_test_pred_pca = pca.predict(X_test)  # outlier labels (0 or 1)\n",
    "y_test_scores_pca = pca.decision_function(X_test)  # outlier scores\n",
    "\n",
    "plt.hist(y_train_scores_pca, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.xlabel('PCA outlier score')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA\n",
    "kpca = KPCA_PYOD(n_components=2, kernel='rbf', gamma=0.15, contamination=contamination)\n",
    "kpca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "y_train_pred_kpca = kpca.labels_\n",
    "y_train_scores_kpca = kpca.decision_scores_\n",
    "\n",
    "# get the prediction labels and outlier scores of the test data\n",
    "y_test_scores_kpca = kpca.decision_function(X_test)\n",
    "y_test_pred_kpca = kpca.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction on the test data\n",
    "y_test_pred_kpca = kpca.predict(X_test)  # outlier labels (0 or 1)\n",
    "y_test_scores_kpca = kpca.decision_function(X_test)  # outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train_scores_kpca, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.xlabel('KPCA outlier score')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test other Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of kernel functions and parameters to try\n",
    "\"\"\"kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "gammas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Perform kernelPCA\n",
    "# Initialize a subplot grid to plot the results\n",
    "fig, axs = plt.subplots(len(kernels), len(gammas), figsize=(15, 15), constrained_layout=True)\n",
    "\n",
    "# Loop over the kernels and gammas and perform KPCA\n",
    "for i, kernel in enumerate(kernels):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        # Initialize the KPCA transformer and fit the data\n",
    "        kpca = KernelPCA(n_components=2, kernel=kernel, gamma=gamma)\n",
    "        X_kpca = kpca.fit_transform(X_train)\n",
    "\n",
    "        # Plot the results\n",
    "        axs[i, j].scatter(X_kpca[:, 0], X_kpca[:, 1], c=y_train, cmap='viridis', alpha=0.8)\n",
    "        axs[i, j].set_title(f'{kernel} kernel, gamma={gamma}')\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary PCA and Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_pca = pca.threshold_\n",
    "threshold_kpca = kpca.threshold_\n",
    "\n",
    "print(\"The threshold of the PCA method for the defined comtanimation rate:\" , threshold_pca)\n",
    "print(\"The threshold of the KPCA method for the defined comtanimation rate:\" , threshold_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stat_threshold(df,pred_score, threshold):\n",
    "    # Let's see how many '0's and '1's.\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
    "\n",
    "    # Now let's show the summary statistics:\n",
    "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
    "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
    "    return (stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stat_threshold(X_train,y_train_scores_pca, threshold_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stat_threshold(X_train,y_train_scores_kpca, threshold_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual_pred_pca = pd.DataFrame({'Actual': y_test, 'Anomaly_Score': y_test_scores_pca})\n",
    "Actual_pred_pca['Pred'] = np.where(Actual_pred_pca['Anomaly_Score']< threshold_pca,0,1)\n",
    "pd.crosstab(Actual_pred_pca['Actual'],Actual_pred_pca['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual_pred_kpca = pd.DataFrame({'Actual': y_test, 'Anomaly_Score': y_test_scores_kpca})\n",
    "Actual_pred_kpca['Pred'] = np.where(Actual_pred_kpca['Anomaly_Score']< threshold_kpca,0,1)\n",
    "pd.crosstab(Actual_pred_kpca['Actual'],Actual_pred_kpca['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit PCA on training data\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# create a scatter plot of the projected data\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit KernelPCA on training data\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf', gamma=0.01)\n",
    "X_train_kpca = kpca.fit_transform(X_train)\n",
    "\n",
    "# create a scatter plot of the projected data\n",
    "plt.scatter(X_train_kpca[:, 0], X_train_kpca[:, 1], c=y_train, cmap='viridis')\n",
    "plt.xlabel('Kernel Principal Component 1')\n",
    "plt.ylabel('Kernel Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_reduced[dataset_reduced.columns[:-1]]\n",
    "y = dataset_reduced['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "X_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the one class support vector machine (SVM) model\n",
    "one_class_svm = OneClassSVM(nu=0.01, kernel = 'rbf', gamma = 'auto').fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the anomalies\n",
    "prediction = one_class_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the anomalies' values to make it consistent with the true values\n",
    "prediction = [1 if i==-1 else 0 for i in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model performance\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy score predicted is {}\".format(accuracy_score(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scores for the testing dataset\n",
    "score = one_class_svm.score_samples(X_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the score for 2% of outliers\n",
    "score_threshold = np.percentile(score, 2)\n",
    "score_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the score for 2% of outliers\n",
    "score_threshold = np.percentile(score, 2)\n",
    "print(f'The customized score threshold for 2% of outliers is {score_threshold:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model performance at 2% threshold\n",
    "customized_prediction = [1 if i < score_threshold else 0 for i in score]\n",
    "# # Check the prediction performance\n",
    "print(classification_report(y_test, customized_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
