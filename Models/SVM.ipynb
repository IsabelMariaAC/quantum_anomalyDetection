{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a996fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipynb\n",
    "%pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0963818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Model and performance\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(palette='rainbow', context='talk')\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run EDA.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcc1bb78",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inandout(outlier,inlier,target, df_,frac_out):\n",
    "    df = df_.copy()\n",
    "    class_label = target\n",
    "    out_classes = pd.DataFrame()\n",
    "    #Select the class you want to be outlier\n",
    "    for out in outlier:\n",
    "        out_class = out\n",
    "        outliers_samples = df[df.target == out_class]\n",
    "        outliers_samples = outliers_samples.sample(frac = frac_out)\n",
    "        out_classes = pd.concat([out_classes, outliers_samples], ignore_index=False).sort_index()\n",
    "        #print(out_classes.shape)\n",
    "    \n",
    "    #print(out_classes.shape)\n",
    "    in_class = inlier\n",
    "    inlier_samples = df[df.target == in_class]\n",
    "\n",
    "    # Concatenate the modified outliers samples with the original inlier samples\n",
    "    y = pd.concat([inlier_samples.target, out_classes.target], ignore_index=False).sort_index()\n",
    "    y =[1 if i==inlier else 0 for i in y]\n",
    "    print(Counter(y))\n",
    "    x = pd.concat([inlier_samples.drop(columns=class_label), out_classes.drop(columns=class_label)], ignore_index=False).sort_index()\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_TestTrain_normalize(x,y):\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=43,stratify=y)\n",
    "\n",
    "        # Check the number of records\n",
    "    print('The number of records in the training dataset is', X_train.shape[0])\n",
    "    print('The number of records in the test dataset is', X_test.shape[0])\n",
    "    print(Counter(y_train))\n",
    "    \n",
    "    # Assuming your dataset is a 2D array or a pandas DataFrame\n",
    "    # Initialize the scaler\n",
    "    #scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_nu(X_train,y_train,nu):\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'gamma': [0.1, 0.5, 1.0],  # range of gamma values to try\n",
    "        'kernel': ['linear', 'rbf','sigmoid','poly']  # types of kernels to try\n",
    "    }\n",
    "\n",
    "    # Create an instance of the OneClassSVM\n",
    "    model = OneClassSVM(nu=nu)\n",
    "    #scoring = accuracy_score(y_test, prediction)\n",
    "    # Create a grid search object\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='accuracy',cv=5)\n",
    "\n",
    "    # Perform grid search on your data\n",
    "    grid_search.fit(X_train, y_train)  # X_train and y_train are your training data\n",
    "\n",
    "    # Get the best parameters and accuracy score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(\"Best Parameters: \", best_params)\n",
    "    print(\"Best Accuracy Score: \", best_score)\n",
    "\n",
    "    return best_params,best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_Kernel(X_train,X_test,y_train,y_test,gamma,nu,name):\n",
    "    classical_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    ds1_f1 = []\n",
    "\n",
    "    for kernel in classical_kernels:\n",
    "        # Train the one class support vector machine (SVM) model\n",
    "        one_class_svm = OneClassSVM(nu=nu, kernel = kernel, gamma = gamma).fit(X_train)\n",
    "        # Predict the anomalies\n",
    "        prediction_ = one_class_svm.predict(X_test)\n",
    "        prediction_ = [False if i==-1 else True for i in prediction_]\n",
    "        print(\"{} kernel classification f1 score is {}\".format(kernel,f1_score(y_test, prediction_)))\n",
    "        ds1_f1.append(f1_score(y_test, prediction_))\n",
    "\n",
    "    # Set the width of the bars\n",
    "    bar_width = 0.4\n",
    "\n",
    "    # Create a list of x positions for the bars\n",
    "    x_pos = range(len(classical_kernels))\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.bar(x_pos, ds1_f1, width=bar_width)\n",
    "\n",
    "    # Set the x-axis labels\n",
    "    plt.xticks(x_pos, classical_kernels)\n",
    "\n",
    "    # Set the y-axis label\n",
    "    plt.ylabel('F1 Score')\n",
    "\n",
    "    # Set the title of the graph\n",
    "    plt.title('F1 Score for Different Kernels ('+name+' Dataset)')\n",
    "\n",
    "    # Add the rounded values on top of each bar\n",
    "    for i, value in enumerate(ds1_f1):\n",
    "        rounded_value = round(value, 3)  # Round off to three decimal points\n",
    "        plt.text(i, value, str(rounded_value), ha='center', va='bottom')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAll_kernelsSVM(X_train,X_test,y_train,y_test, gamma,kernel,nu):\n",
    "    \n",
    "    #ds1_f1 = []\n",
    "    predictions = []\n",
    "    predictionsTrains = []\n",
    "\n",
    "    \n",
    "    # Train the one class support vector machine (SVM) model\n",
    "    one_class_svm = OneClassSVM(nu=nu,kernel = kernel,gamma=gamma).fit(X_train)\n",
    "        \n",
    "    # Predict the anomalies\n",
    "    test_prediction = one_class_svm.predict(X_test)\n",
    "    #print(\"This is the test prediction: \"+str(test_prediction))\n",
    "    test_prediction = [0 if i==-1 else 1 for i in test_prediction]\n",
    "    print(\"{} kernel accurnacy is {}\".format(kernel,accuracy_score(y_test, test_prediction)))\n",
    "    print(\" The accurnacy is \"+str(f1_score(y_test, test_prediction)))\n",
    "    #print(\"This is the test prediction modified: \"+str(prediction))\n",
    "    #ds1_f1.append(f1_score(y_test, prediction))\n",
    "    \n",
    "\n",
    "    train_prediction = one_class_svm.predict(X_train)\n",
    "    #print(\"This is the train prediction: \"+str(train_prediction))\n",
    "    predictionTrain = [0 if i==-1 else 1 for i in train_prediction]\n",
    "    #print(\"This is the train prediction modified: \"+str(predictionTrain))\n",
    "    \n",
    "\n",
    "    return test_prediction,predictionTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa647f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterPlot(X_test,y_test,test_prediction,filename,feature1,feature2):    \n",
    "# Put the testing dataset and predictions in the same dataframe\n",
    "    X_test_ = X_test.copy()\n",
    "    y_test_ = y_test.copy()\n",
    "    df_test = pd.DataFrame(X_test_)\n",
    "    df_test['y_test'] = np.array(y_test_)\n",
    "    df_test['one_class_svm_prediction'] = test_prediction\n",
    "    # Visualize the actual and predicted anomalies\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Well-classified samples\n",
    "    well_classified = df_test[df_test['y_test'] == df_test['one_class_svm_prediction']]\n",
    "    ax.scatter(well_classified[feature1], well_classified[feature2], c='green', label='Well Classified')\n",
    "\n",
    "    # Wrongly classified samples\n",
    "    wrong_classified = df_test[df_test['y_test'] != df_test['one_class_svm_prediction']]\n",
    "    ax.scatter(wrong_classified[feature1], wrong_classified[feature2], c='red', label='Wrong Classification')\n",
    "\n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.set_title('Well Classified vs Wrong Classification')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec63984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallPlot(y_test,test_prediction,filename):    \n",
    "    \n",
    "    #labels = y_test\n",
    "    #calculate precision and recall\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, test_prediction)\n",
    "\n",
    "    #create precision recall curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "\n",
    "    #add axis labels to plot\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.set_xlabel('Recall')\n",
    "\n",
    "    #display plot\n",
    "    #plt.show()\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RocCurve_plot(y_train, y_test, train_prediction,test_prediction,filename):\n",
    "    \n",
    "    train_fpr, train_tpr, tr_thresholds = roc_curve(y_train, train_prediction)\n",
    "    test_fpr, test_tpr, te_thresholds = roc_curve(y_test, test_prediction)\n",
    "    plt.grid()\n",
    "    plt.plot(train_fpr, train_tpr, label=\" AUC TRAIN =\"+str(auc(train_fpr, train_tpr)))\n",
    "    plt.plot(test_fpr, test_tpr, label=\" AUC TEST =\"+str(auc(test_fpr, test_tpr)))\n",
    "    plt.plot([0,1],[0,1],'g--')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"AUC(ROC curve)\")\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa5c7068",
   "metadata": {},
   "source": [
    "# IRIS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0216da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iris, x ,y = irisData ()\n",
    "target = 'target'\n",
    "print(\"The dataset selected has shape: \" + str(dataset_iris.shape) + \" and for each class \"+ str(Counter(dataset_iris[target])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a07de277",
   "metadata": {},
   "source": [
    "## Apply OCC-SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ea8eb74",
   "metadata": {},
   "source": [
    "### For multi-class datasets we need to select 1 target class and then set an smaller amount of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91603f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class = [0,2]\n",
    "in_class = 1\n",
    "outPer = 0.2\n",
    "x_,y_ = split_inandout(out_class,in_class,target,dataset_iris,0.1)\n",
    "X_train, X_test, y_train, y_test = split_TestTrain_normalize(x_,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax[0].hist(y_train)\n",
    "ax[0].set_title(\"Train labels\")\n",
    "ax[1].hist(y_test)\n",
    "ax[1].set_title(\"Test labels\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "649efcf1",
   "metadata": {},
   "source": [
    "### Now we proceed with the OCC-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fe4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param,accurancy = select_best_nu(X_train,y_train,outPer)\n",
    "best_Kernel(X_train,X_test,y_train,y_test,param['gamma'],outPer,'Iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction,train_prediction = runAll_kernelsSVM(X_train, X_test,y_train, y_test,'auto',param['kernel'],outPer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f220f621",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../figures/IrisData'\n",
    "\n",
    "scatterPlot(X_test,y_test,test_prediction,filename+'_scatterPlot',0,1)\n",
    "recallPlot(y_test,test_prediction,filename+'_recallPlot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df704264",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurve_plot(y_train, y_test, train_prediction,test_prediction,filename+'_ROCplot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72576927",
   "metadata": {},
   "source": [
    "# VOWEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534874c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowelDataset, x ,y = vowelData ()\n",
    "vowelDataset = vowelDataset.rename(columns={'feature12':'target'})\n",
    "#for vowels dataset\n",
    "target = 'target'\n",
    "\n",
    "print(\"The dataset selected has shape: \" + str(vowelDataset.shape) + \" and for each class \"+ str(Counter(vowelDataset[target])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41c877c5",
   "metadata": {},
   "source": [
    "## Apply OCC-SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca8e2b71",
   "metadata": {},
   "source": [
    "### For multi-class datasets we need to select 1 target class and then set an smaller amount of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca61727",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class = [2,5,6,7,9]\n",
    "in_class = 1\n",
    "outPer = 0.1\n",
    "x,y = split_inandout(out_class,in_class,target,vowelDataset,0.02)\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = split_TestTrain_normalize(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "ax[0].hist(y_train)\n",
    "ax[0].set_title(\"Train labels\")\n",
    "ax[1].hist(y_test)\n",
    "ax[1].set_title(\"Test labels\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4358cc94",
   "metadata": {},
   "source": [
    "### Now we proceed with the OCC-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param,accurancy = select_best_nu(X_train,y_train,outPer)\n",
    "best_Kernel(X_train,X_test,y_train,y_test,param['gamma'],outPer,'Vowel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction,train_prediction = runAll_kernelsSVM(X_train, X_test,y_train, y_test,param['gamma'],param['kernel'],outPer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb82f35e",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../figures/vowelData'\n",
    "\n",
    "scatterPlot(X_test,y_test,test_prediction,filename+'_scatterPlot',4,5)\n",
    "recallPlot(y_test,test_prediction,filename+'_recallPlot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurve_plot(y_train, y_test, train_prediction,test_prediction,filename+'_ROCplot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "413958fe",
   "metadata": {},
   "source": [
    "# BREAST CANCER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset, x ,y = breastcancerData()\n",
    "target = 'target'\n",
    "\n",
    "print(\"The dataset selected has shape: \" + str(breast_dataset.shape) + \" and for each class \"+ str(Counter(breast_dataset[target])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93ff6b4f",
   "metadata": {},
   "source": [
    "## Apply OCC-SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f88e31ae",
   "metadata": {},
   "source": [
    "### For multi-class datasets we need to select 1 target class and then set an smaller amount of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792130bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class = [0]\n",
    "in_class = 1\n",
    "outPer = 0.2\n",
    "x_,y_ = split_inandout(out_class,in_class,target,breast_dataset,outPer)\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = split_TestTrain_normalize(x_,y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "ax[0].hist(y_train)\n",
    "ax[0].set_title(\"Train labels\")\n",
    "ax[1].hist(y_test)\n",
    "ax[1].set_title(\"Test labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions (the dataset now has a dimensionality of 31 attributes)\n",
    "n_dim = 12 #number of qubits we want to use\n",
    "pca = PCA(n_components=n_dim).fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51b8be1f",
   "metadata": {},
   "source": [
    "### Now we proceed with the OCC-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "param,accurancy = select_best_nu(X_train,y_train,outPer)\n",
    "best_Kernel(X_train,X_test,y_train,y_test,param['gamma'],outPer,'Breast Cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75852d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction,train_prediction = runAll_kernelsSVM(X_train, X_test,y_train, y_test,'auto',param['kernel'],outPer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db6e8d38",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../figures/BreastData'\n",
    "\n",
    "scatterPlot(X_test,y_test,test_prediction,filename+'_scatterPlot',0,1)\n",
    "recallPlot(y_test,test_prediction,filename+'_recallPlot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurve_plot(y_train, y_test, train_prediction,test_prediction,filename+'_ROCplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30aef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
