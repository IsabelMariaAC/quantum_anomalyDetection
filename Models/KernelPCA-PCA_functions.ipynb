{"cells":[{"attachments":{},"cell_type":"markdown","id":"28c69647","metadata":{},"source":["# PCA and KernelPCA\n","Here is the implementation of PCA and KPCA using PyOD and Scikit-learn for Anomaly Detection\n"]},{"attachments":{},"cell_type":"markdown","id":"a6c7fad5","metadata":{},"source":["```\n","References PCA,KPCA: \n","1. Hoffman, Kernel PCA as Novelty Detecion: https://www.sciencedirect.com/science/article/abs/pii/S0031320306003414\n","2. http://videolectures.net/ecmlpkdd08_lazarevic_dmfa/\n","3. http://videolectures.net/kdd2010_krogel_odt/\n","4. https://pyod.readthedocs.io/en/latest/\n","5. https://scikit-learn.org/stable/\n","6. https://github.com/Nmerrillvt/kPCA\n","7. https://github.com/Quantumgunhee/VQOCC\n","8. https://github.com/GuansongPang/ADRepository-Anomaly-detection-datasets/tree/main\n","9. https://www.heikohoffmann.de/kpca.html\n","\n","```"]},{"attachments":{},"cell_type":"markdown","id":"f28d1789","metadata":{},"source":["<font color='white'> Define **functions** </font>"]},{"cell_type":"code","execution_count":1,"id":"74dfdaed","metadata":{},"outputs":[],"source":["# Import the necessary libraries.\n","import pandas as pd\n","import numpy as np\n","from numpy import reshape\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import seaborn as sns\n","\n","!pip install -q pyod            \n","# Install PyOD. The PyOD library provides several outlier detection methods that can be used\n","# !pip install --upgrade pyod  \n","# or update if needed\n","\n","from pyod.models.pca import PCA as PCA_PYOD\n","from pyod.models.kpca import KPCA as KPCA_PYOD\n","\n","from sklearn.decomposition import PCA, KernelPCA\n","from sklearn.linear_model import LogisticRegression\n","\n","from pyod.utils.data import evaluate_print\n","from pyod.utils.example import visualize\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, precision_recall_curve, classification_report, roc_curve, auc, roc_auc_score\n","\n","from sklearn.datasets import load_iris, load_breast_cancer\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","from collections import Counter"]},{"attachments":{},"cell_type":"markdown","id":"3765cd42","metadata":{},"source":["**Outlier Detection** based on PyOD library and Hoffman's Novelty Detection"]},{"attachments":{},"cell_type":"markdown","id":"7ffecb2b","metadata":{},"source":["FUNCTIONS PyOD:  PCA & Kernel-PCA Outlier Detection:\n","Train the model with normal and abnormal data. Then trying a test set and  making decision if it is outlier or not based on Hoffmans Paper for Novelty Detection and PyOD documentation."]},{"cell_type":"code","execution_count":2,"id":"231fbc66","metadata":{},"outputs":[],"source":["def pca_kpca_with_metrics(model, X_train, y_train, X_test, y_test, contamination=0.1,\n","                            kernel='rbf', gamma=0.1, degree=3, coef0=1):\n","\n","  if model=='pca':\n","    # Fit the model\n","    model_ad = PCA_PYOD(n_components=None, contamination=contamination)\n","    model_ad.fit(X_train,y=None)\n","\n","    n_components = model_ad.n_components_\n","    components = model_ad.components_\n","\n","    print(\"The non-0s PCA components are: \",n_components)\n","    # print(\"The components: \\n\", components)\n","\n","    # exp_var = model_ad.explained_variance_\n","    exp_var_rat = model_ad.explained_variance_ratio_\n","\n","    plot_explained_variance(exp_var_rat)\n","    n_components = explained_variance_threshold(exp_var_rat, n_components)\n","\n","    model_ad = PCA_PYOD(n_components=n_components, contamination=contamination)\n","  else: \n","    if model=='kpca':\n","      n_components=2\n","      model_ad = KPCA_PYOD(n_components=n_components, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, contamination=contamination)   \n","    else:\n","      print(\"wrong input model\")\n","      return\n","  \n","  model_ad.fit(X_train,y=None)\n","\n","  threshold_model_ad = model_ad.threshold_\n","  print(\"The threshold of the PCA method for the given contamination rate:\" , threshold_model_ad)\n","\n","  y_train_pred = model_ad.predict(X_train)\n","  y_train_scores= model_ad.decision_function(X_train)\n","\n","  y_test_pred = model_ad.predict(X_test) # outlier labels (0 or 1)\n","  y_test_scores = model_ad.decision_function(X_test) #outlier scores\n","\n","  print(\"\\nTrain-set with the threshold:\\n\")\n","  plot_anomalies_with_threshold(y_train_scores, threshold_model_ad)\n","  print(\"Another option to choose better threshold from the above plot.\\nThen run again for other contamination for better results.\\n\")\n","  print(\"\\nTest-set with the threshold:\\n\")\n","  plot_anomalies_with_threshold(y_test_scores, threshold_model_ad)\n","\n","  print(descriptive_stat_threshold(X_train, y_train_scores, threshold_model_ad))\n","  print(\"\\n\")\n","  print(descriptive_stat_threshold(X_test, y_test_scores, threshold_model_ad))\n","  print(\"\\n\")\n","\n","  y_test_prob = model_ad.predict_proba(X_test, method='linear', return_confidence=False)[:, 1]\n","\n","  calculate_metrics(y_test, y_test_scores, y_test_pred)\n","  calculate_metrics(y_train, y_train_scores, y_train_pred)\n","\n","  print(evaluate_print('\\nFor test data:', y_test, y_test_scores))\n","\n","# Function to plot the explained variance ratio\n","def plot_explained_variance(exp_var_ratio):\n","\n","  end = len(exp_var_ratio)+1\n","  plt.figure(figsize=(9, 6))\n","  plt.plot(range(1, end), exp_var_ratio*100)\n","  plt.xlabel('Principal Component ')\n","  plt.ylabel('Explained Variance percentage (%)')\n","  plt.xticks(range(1, end))\n","  plt.show()\n","\n","# Function to plot the explained variance ratio with the selected cumulative %\n","def explained_variance_threshold(exp_var_ratio, number_components):\n","\n","  cum_exp_var = np.cumsum(exp_var_ratio) * 100\n","  end = number_components+1\n","  plt.bar(range(1, end), exp_var_ratio * 100, align='center', label='Individual explained variance')\n","  plt.step(range(1, end), cum_exp_var, where='mid', label='Cumulative explained variance', color='red')\n","  plt.axhline(y=90, color='gray', linestyle='--', linewidth=1)\n","  plt.text(end, 90, '90%', color='gray', fontsize=10, va='center')\n","  plt.ylabel('Explained variance percentage (%)')\n","  plt.xlabel('Principal component')\n","  plt.legend(loc='best')\n","  plt.xticks(ticks=range(1, end))\n","  plt.tight_layout()\n","  plt.show()\n","  # The number of components with the pre-selected % of cumulative %\n","  # Maybe it is better to increase it to 95% instead of 90%\n","  number_components = np.where(cum_exp_var > 90)[0][0] + 1\n","  print(\"Number of principal components needed to explain 90% of variance:\", number_components)\n","\n","  # Returns the number of components\n","  return number_components\n","\n","# Function that plots the histogram of anomaly scores of the test-set with the threshold\n","def plot_anomalies_with_threshold(y_scores, threshold):\n","\n","  plt.hist(y_scores, bins=50) \n","  plt.axvline(x=threshold, color='red', linestyle='--', linewidth=2)\n","  plt.text(threshold, max([list(y_scores).count(x) for x in set(y_scores)]),'Threshold', color='red', fontsize=10, va='center')\n","  plt.title(\"Histogram with the threshold\")\n","  plt.xlabel('Anomaly score')\n","  plt.show()\n","  print(\"\\n\")\n","\n","# Function that gives a table with statistics about the given test-set (Anomaly scores, Avg, count, count%)\n","def descriptive_stat_threshold(df, pred_score, threshold):\n","\n","  df = pd.DataFrame(df)\n","  df['Anomaly_Score'] = pred_score\n","  df['Group'] = np.where(df['Anomaly_Score']<= threshold, 'Normal', 'Outlier')\n","\n","  cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n","  cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n","  stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n","  stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n","  return (stat)\n","\n","# Function to plot the Confussion matrix for the given test-set\n","def conf_matrix(y_true, y_pred, labels=None, title='Confusion Matrix'):\n","\n","  cm = confusion_matrix(y_true, y_pred, labels=labels)\n","  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","  fig, ax = plt.subplots(figsize=(8, 6))\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","  disp.plot(include_values=True, cmap='Blues', ax=ax, xticks_rotation='horizontal')\n","  ax.set_title(title)\n","  ax.set_xlabel('Predicted Label')\n","  ax.set_ylabel('True Label')\n","  plt.show()\n","  return cm\n","\n","# Function that plots the RocCurve for the given test-set\n","def roccurve(y_true, y_scores):\n","\n","  fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","  auc_score = auc(fpr, tpr)\n","  plt.figure(figsize=(9, 6))\n","  plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\n","  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title('Receiver Operating Characteristic')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()\n","  print(\"\\n\")\n","\n","# Function that Prints and plots a lot of Metrics\n","def calculate_metrics(y_true, pred_scores, y_pred):\n","\n","  # Confusion matrix\n","  print('Confusion Matrix:\\n')\n","  cm = conf_matrix(y_true, y_pred)\n","  tn, fp, fn, tp = cm.ravel()\n","      \n","  # Calculate the AUC-ROC\n","  auc_roc = roc_auc_score(y_true, pred_scores)\n","  \n","  # ROC_Curve\n","  roccurve(y_true, pred_scores)\n","\n","  accuracy = (tp+tn)/(tp+fp+tn+fn)\n","  print(\"Accuracy: \", accuracy)\n","\n","  precision = (tp)/(tp+fp)\n","  print(\"Precision: \", precision)\n","\n","  recall = (tp)/(tp+fn)\n","  print(\"Recall: \", recall)\n","\n","  f1score = 2*(precision*recall)/(precision+recall)\n","  print(\"F1 Score: \", f1score)\n","\n","  print(f'AUC-ROC: {auc_roc:.4f}')\n"]},{"attachments":{},"cell_type":"markdown","id":"e774a82f","metadata":{},"source":["**Novelty Detection** Hoffman's Novelty Detection"]},{"cell_type":"code","execution_count":4,"id":"559ba767","metadata":{},"outputs":[],"source":["# TODO: A better decision for PCA method, the KernelPCA method is base on Hoffmans Novelty detection\n","\n","def function_AD(model, \n","                X_train, y_train, X_test, y_test, \n","                n_components=None, \n","                kernel='rbf', \n","                gamma=None, \n","                degree=3, \n","                coef0=1, \n","                contamination=0, \n","                outlier=0,\n","                analysis=False):\n","  \n","  # Selection between PCA and KernelPCA\n","  if model=='pca':\n","\n","    model_ad = PCA(n_components=None)                                         # Create the model for PCA\n","    model_ad.fit(X_train,y=None)                                              # Fit the model with the given train-set (the model should contain only the normal class)\n","    n_components = model_ad.n_components_                                     # The total number of components (For PCA are the number of the features)\n","    print(\"The non-0s PCA components are: \\n\",n_components)\n","    components = model_ad.components_                                         # The components\n","    exp_var = model_ad.explained_variance_                                    # Here is the explained variance for each componant\n","    exp_var_rat = model_ad.explained_variance_ratio_                          # Here is the explained variance ratio for each componant\n","\n","\n","    plot_explained_variance_AD(exp_var_rat)                                      # Here is the explained variance for each component\n","    n_components = explained_variance_threshold_AD(exp_var_rat, n_components)    # Select the components tha discribe the 90% of cumulative explained_variance\n","\n","    # Re-fit the model with the selected components\n","    if n_components == 1: n_components = 2\n","    model_ad = PCA(n_components=n_components)\n","\n","  else: \n","    if model=='kpca':\n","      # TODO: The selected components for kpca is 2, but we can try a gridsearch in order to distinguish which number of components is better\n","      n_components=2\n","\n","      \n","      model_ad = KernelPCA(n_components=n_components, kernel=kernel,          # Create the model\n","                           gamma=gamma, degree=degree, coef0=coef0, fit_inverse_transform=True)\n","    else:\n","      print(\"The model you can use are PCA and KernelPCA as: pca or kpca respectively\")\n","      return\n","\n","  # Fit the model with the X_train and transforming the X_train into the selected number of components and then reconstructed.\n","  X_train_reconstructed = model_ad.inverse_transform(model_ad.fit_transform(X_train))\n","  \n","  # Reduce and reconstruct the test-data back to its original \n","  X_test_reduced = model_ad.transform(X_test)\n","  X_test_reconstructed = model_ad.inverse_transform(X_test_reduced)\n","\n","  # Get the reconstruction Errors\n","  rec_errors_test = reconstruction_errors_AD(X_test, X_test_reconstructed)\n","  rec_errors_train = reconstruction_errors_AD(X_train, X_train_reconstructed)\n","\n","  # Calculate the Novelty Scores \n","  anom_scores = anomaly_scores_AD(rec_errors_train, rec_errors_test)\n","\n","  # Threshold\n","  threshold = threshold_ratio_AD(X_train, y_test, rec_errors_train, outlier=outlier, contamination=contamination, anom_scores = anom_scores)\n","\n","  # Classify the test data as normal or anomalous based on the reconstruction error and the selected threshold\n","  y_pred = [1 if e > threshold else 0 for e in rec_errors_test]\n","\n","  if model=='pca' or analysis==False:\n","\n","    # Plot the score of anomalies and the threshold\n","    plot_anomalies_with_threshold_AD(anom_scores, threshold)\n","\n","    # Plot the true normal classes of the selected X_train into two Principal Components of the transformed Data\n","    plt.figure(figsize=(7, 6))\n","    plt.scatter(X_test_reduced[:, 0], X_test_reduced[:, 1], c=y_test, cmap='viridis')\n","    plt.xlabel('PC1')\n","    plt.ylabel('PC2')\n","    plt.title('The first 2 PC of the true test-set')\n","    plt.show()\n","\n","    # Plot the predicted normals and the predicted anomalies of the selected X_test into two Principal Components of the transformed Data\n","    plt.figure(figsize=(7, 6))\n","    plt.scatter(X_test_reduced[:, 0], X_test_reduced[:, 1], c=y_pred, cmap='viridis')\n","    plt.xlabel('PC1')\n","    plt.ylabel('PC2')\n","    plt.title('The first 2 PC of the predicted test-set')\n","    plt.show()\n","\n","    # Print informations about the given test-set\n","    descriptive_stat_threshold_AD(X_test, anom_scores, threshold)\n","    \n","    # Print and Plot all the Metrics\n","    calculate_metrics_AD(X_test, y_test, anom_scores, y_pred) \n","    # print(f1_score(y_test, y_pred))\n","  else:\n","    return roc_auc_score(y_test, anom_scores), f1_score(y_test, y_pred)\n","\n","\n","    \n","# Function that calculates the reconstruction errors\n","def reconstruction_errors_AD(X, X_reconstructed):\n","  # Calculate the reconstruction error for each data point\n","  reconstruction_errors = np.mean((X - X_reconstructed) ** 2, axis=1)\n","  return reconstruction_errors\n","\n","# Functions that returns the anomaly scores\n","def anomaly_scores_AD(reconstruction_errors_train, reconstruction_errors_test):\n","  # Calculate the Novelty Scores for each data point of the test-set\n","  mean_error = np.mean(reconstruction_errors_train)\n","  std_error = np.std(reconstruction_errors_train)\n","  normalized_error_test = (reconstruction_errors_test - mean_error) / std_error\n","  return np.abs(normalized_error_test)\n","\n","# Function that returns the threshold\n","# Here I am not sure if is the correct way but we can find the best threshold for having the best F-1 score if the contamination=0. \n","# Otherwise we can set it based a given threshold or as a contamination (% of outliers or anomalies in the test set)\n","def threshold_ratio_AD(X_train, y_true, reconstruction_errors, outlier=0, contamination=0, anom_scores = 0):\n","  if contamination==-1:\n","\n","    # Calculate precision and recall for different thresholds\n","    precision, recall, thresholds = precision_recall_curve(y_true, anom_scores)\n","\n","    # Calculate the F1 score for each threshold\n","    f1_scores = 2 * (precision * recall) / (precision + recall)\n","       \n","    # Find the index of the threshold that maximizes the F1 score\n","    optimal_idx = np.argmax(f1_scores)\n","       \n","    # Get the optimal threshold\n","    optimal_threshold = thresholds[optimal_idx]\n","    print(\"The optimum threshold of the PCA method:\", optimal_threshold)\n","    threshold = optimal_threshold\n","\n","  elif contamination==0:\n","    mean_error = np.mean(reconstruction_errors)\n","    std_error = np.std(reconstruction_errors)\n","    normalized_error = (reconstruction_errors - mean_error) / std_error\n","    threshold = mean_error + 2.5 * std_error\n","\n","  elif contamination>0 and contamination<0.5:\n","    serr = np.sort(reconstruction_errors)\n","    threshold = serr[X_train.shape[0]-outlier-1]\n","\n","  else:\n","    print(\"Not correct contamination ratio\")\n","\n","  return threshold\n","\n","# Function to plot the explained variance ratio\n","def plot_explained_variance_AD(exp_var_ratio):\n","\n","  end = len(exp_var_ratio)+1\n","  plt.figure(figsize=(9, 6))\n","  plt.plot(range(1, end), exp_var_ratio*100)\n","  plt.xlabel('Principal Component ')\n","  plt.ylabel('Explained Variance percentage (%)')\n","  plt.xticks(range(1, end))\n","  plt.show()\n","\n","# Function to plot the explained variance ratio with the selected cumulative %\n","def explained_variance_threshold_AD(exp_var_ratio, number_components):\n","\n","  cum_exp_var = np.cumsum(exp_var_ratio) * 100\n","  end = number_components+1\n","  plt.bar(range(1, end), exp_var_ratio * 100, align='center', label='Individual explained variance')\n","  plt.step(range(1, end), cum_exp_var, where='mid', label='Cumulative explained variance', color='red')\n","  plt.axhline(y=90, color='gray', linestyle='--', linewidth=1)\n","  plt.text(end, 90, '90%', color='gray', fontsize=10, va='center')\n","  plt.ylabel('Explained variance percentage (%)')\n","  plt.xlabel('Principal component')\n","  plt.legend(loc='best')\n","  plt.xticks(ticks=range(1, end))\n","  plt.tight_layout()\n","  plt.show()\n","  # The number of components with the pre-selected % of cumulative %\n","  # Maybe it is better to increase it to 95% instead of 90%\n","  number_components = np.where(cum_exp_var > 90)[0][0] + 1\n","  print(\"Number of principal components needed to explain 90% of variance:\", number_components)\n","\n","  # Returns the number of components\n","  return number_components\n","\n","# Function that plots the histogram of anomaly scores of the test-set with the threshold\n","def plot_anomalies_with_threshold_AD(y_scores, threshold):\n","\n","  plt.hist(y_scores, bins=50) \n","  plt.axvline(x=threshold, color='red', linestyle='--', linewidth=2)\n","  plt.text(threshold, max([list(y_scores).count(x) for x in set(y_scores)]),'Threshold', color='red', fontsize=10, va='center')\n","  plt.title(\"Histogram with the threshold\")\n","  plt.xlabel('Anomaly score')\n","  plt.show()\n","  print(\"\\n\")\n","\n","# Function that gives a table with statistics about the given test-set (Anomaly scores, Avg, count, count%)\n","def descriptive_stat_threshold_AD(df, pred_score, threshold):\n","\n","  df = pd.DataFrame(df)\n","  df['Anomaly_Score'] = pred_score\n","  df['Group'] = np.where(df['Anomaly_Score']<= threshold, 'Normal', 'Novelty')\n","\n","  cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n","  cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n","  stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n","  stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n","  return (stat)\n","\n","# Function to plot the Confussion matrix for the given test-set\n","def conf_matrix_AD(y_true, y_pred, labels=None, title='Confusion Matrix'):\n","\n","  cm = confusion_matrix(y_true, y_pred, labels=labels)\n","  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","  fig, ax = plt.subplots(figsize=(7, 6))\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","  disp.plot(include_values=True, cmap='Blues', ax=ax, xticks_rotation='horizontal')\n","  ax.set_title(title)\n","  ax.set_xlabel('Predicted Label')\n","  ax.set_ylabel('True Label')\n","  plt.show()\n","  return cm\n","\n","# Function that plots the RocCurve for the given test-set\n","def roccurve_AD(y_true, y_scores):\n","\n","  fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","  auc_score = auc(fpr, tpr)\n","  # plt.figure(figsize=(7, 6))\n","  plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.2f})')\n","  plt.plot([0,1],[0,1],'g--')\n","  plt.legend()\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title(\"AUC(ROC curve)\")  \n","  plt.grid(color='black', linestyle='-', linewidth=0.5)\n","  plt.show()\n","  print(\"\\n\")\n","\n","# Function that Prints and plots a lot of Metrics\n","def calculate_metrics_AD(X_true, y_true, pred_scores, y_pred):\n","\n","  # Confusion matrix\n","  print('Confusion Matrix:\\n')\n","  cm = conf_matrix_AD(y_true, y_pred)\n","      \n","  # Calculate the AUC-ROC\n","  auc_roc = roc_auc_score(y_true, pred_scores)\n","  \n","  # ROC_Curve\n","  roccurve_AD(y_true, pred_scores)\n","\n","  # Calculate the accuracy\n","  accuracy = accuracy_score(y_true, y_pred)\n","\n","  # Calculate the precision\n","  precision = precision_score(y_true, y_pred)\n","\n","  # Calculate the recall\n","  recall = recall_score(y_true, y_pred)\n","\n","  # Calculate the F1 score\n","  f1 = f1_score(y_true, y_pred)\n","\n","  # Print the results\n","  print(f'AUC-ROC: {auc_roc:.4f}')\n","  print(f'Accuracy: {accuracy:.4f}')\n","  print(f'F1 Score: {f1:.4f}')\n","  print(f'Precision: {precision:.4f}')\n","  print(f'Recall: {recall:.4f}')\n","\n","  #return cm, auc_roc, accuracy, f1, precision, recall\n","  \n","def split_data(X, y, chosen_class=0, percentage=0.8):\n","    if chosen_class not in np.unique(y):\n","        raise ValueError(\"Chosen class not found in the target variable.\")\n","  \n","    # Filter X for the chosen class: y = class\n","    X_c = X[y == chosen_class]\n","    y_c = y[y == chosen_class]\n","\n","    # Randomly shuffle the rows of X_c and y_c\n","    random_indices = np.random.permutation(len(X_c))\n","    X_c = X_c[random_indices]\n","    y_c = y_c[random_indices]\n","\n","    # Split X_c and y_c into training and testing sets\n","    train_size = int(percentage * len(X_c))\n","    X_train = X_c[:train_size]\n","    y_train = y_c[:train_size]\n","    X_test_n = X_c[train_size:]\n","    y_test_n = y_c[train_size:]\n","\n","    # Filter X for other classes: y != class\n","    X_new_a = X[y != chosen_class]\n","    y_new_a = y[y != chosen_class]\n","\n","    # Randomly select rows from X_new_a and y_new_a to create X_test_a and y_test_a\n","    select = len(X_test_n)\n","    random_indices = np.random.choice(len(X_new_a), size=select, replace=False)\n","    X_test_a = X_new_a[random_indices]\n","    y_test_a = y_new_a[random_indices]\n","\n","    # Combine X_test_n, X_test_a, y_test_n, and y_test_a to create X_test and y_test\n","    X_test = np.concatenate((X_test_n, X_test_a), axis=0)\n","    y_test = np.concatenate((y_test_n, y_test_a), axis=0)\n","    \n","    return X_train, X_test, X_test_n, X_test_a, y_train, y_test, y_test_n, y_test_a\n"]},{"attachments":{},"cell_type":"markdown","id":"ca89e9a1","metadata":{},"source":["**Park's get the AUC with the mean of mse of each class.**"]},{"cell_type":"code","execution_count":5,"id":"035ac63f","metadata":{},"outputs":[],"source":["def split_data(X, y, chosen_class=0, percentage=0.8):\n","    if chosen_class not in np.unique(y):\n","        raise ValueError(\"Chosen class not found in the target variable.\")\n","  \n","    # Filter X for the chosen class: y = class\n","    X_c = X[y == chosen_class]\n","    y_c = y[y == chosen_class]\n","\n","    # Randomly shuffle the rows of X_c and y_c\n","    random_indices = np.random.permutation(len(X_c))\n","    X_c = X_c[random_indices]\n","    y_c = y_c[random_indices]\n","\n","    # Split X_c and y_c into training and testing sets\n","    train_size = int(percentage * len(X_c))\n","    X_train = X_c[:train_size]\n","    y_train = y_c[:train_size]\n","    X_test_n = X_c[train_size:]\n","    y_test_n = y_c[train_size:]\n","\n","    # Filter X for other classes: y != class\n","    X_new_a = X[y != chosen_class]\n","    y_new_a = y[y != chosen_class]\n","\n","    # Randomly select rows from X_new_a and y_new_a to create X_test_a and y_test_a\n","    select = len(X_test_n)\n","    random_indices = np.random.choice(len(X_new_a), size=select, replace=False)\n","    X_test_a = X_new_a[random_indices]\n","    y_test_a = y_new_a[random_indices]\n","\n","    # Combine X_test_n, X_test_a, y_test_n, and y_test_a to create X_test and y_test\n","    X_test = np.concatenate((X_test_n, X_test_a), axis=0)\n","    y_test = np.concatenate((y_test_n, y_test_a), axis=0)\n","    \n","    return X_train, X_test, X_test_n, X_test_a, y_train, y_test, y_test_n, y_test_a\n","\n","def kernelpca_OCC(X_train, X_test_n, X_test_a, n_components=None, gamma=0.01, kernel=\"rbf\", alpha=0.1):\n","\n","  kernel_pca = KernelPCA(n_components=n_components, kernel=kernel, gamma=gamma, fit_inverse_transform=True, alpha=alpha)\n","  kernel_pca.fit(X_train)\n","\n","  X_train_reconstructed = kernel_pca.inverse_transform(kernel_pca.transform(X_train))\n","  X_test_n_reconstructed = kernel_pca.inverse_transform(kernel_pca.transform(X_test_n))\n","  X_test_a_reconstructed = kernel_pca.inverse_transform(kernel_pca.transform(X_test_a))\n","\n","  n_mse = np.square(np.subtract(X_test_n,X_test_n_reconstructed)).mean(axis=1)\n","  a_mse = np.square(np.subtract(X_test_a,X_test_a_reconstructed)).mean(axis=1)\n","\n","  return n_mse, a_mse\n","\n","def AUC_OC(n_mse, a_mse):\n","  \n","  y_true = np.array([0]*len(n_mse)+[1]*len(a_mse))\n","  y_score = np.r_[n_mse,a_mse]\n","\n","  fpr, tpr, _ = roc_curve(y_true, y_score)\n","  auc_measure = auc(fpr,tpr)\n","\n","  return auc_measure\n","\n","\n","def Kernel_PCA_AUC(X, y, split_percentage=0.8, one_class=-1, kernel_analysis=False):\n","  # Get the unique classes\n","  all_classes = np.unique(y)\n","  print(\"\\nAll different classes: \", all_classes)\n","  \n","  # Count the number of unique classes in y\n","  number_of_classes = len(all_classes)\n","  print(\"\\nNumber of classes: \", number_of_classes)\n","\n","  if (one_class==-1) or (one_class not in all_classes):\n","    # do for all classes\n","    for oc in range(number_of_classes):\n","      X_train, X_test, X_test_n, X_test_a, y_train, y_test, y_test_n, y_test_a = split_data(X, y, oc, split_percentage)\n","      if kernel_analysis==False:\n","        n_mse, a_mse = kernelpca_OCC(X_train, X_test_n, X_test_a)\n","        auc = AUC_OC(n_mse, a_mse)\n","        print(\"\\nFor the class: \", oc)\n","        print(\"\\nAUC: \", auc)\n","      else:\n","        best_auc = 0.0\n","        ooptimum_gamma = 0\n","        for gamma in np.logspace(-10, 10, num=20, base=2):\n","          n_mse, a_mse = kernelpca_OCC(X_train, X_test_n, X_test_a, gamma=gamma)\n","          new_auc = AUC_OC(n_mse, a_mse)\n","          # print(\"\\nFor the class: \", oc)\n","          # print(\"\\n gamma: \", gamma)\n","          # print(\"\\nAUC: \", new_auc)\n","          if new_auc > best_auc :\n","            best_auc = new_auc\n","            optimum_gamma = gamma\n","        print(\"=====================\")\n","        print(\"\\nFor the class: \", oc)\n","        print(\"\\nOptimum gamma: \", optimum_gamma)\n","        print(\"\\nBest AUC: \", best_auc)\n","        print(\"=====================\")\n","  else:\n","      # do for the chosen \n","      X_train, X_test, X_test_n, X_test_a, y_train, y_test, y_test_n, y_test_a = split_data(X, y, one_class, split_percentage)\n","      if kernel_analysis==False:\n","        n_mse, a_mse = kernelpca_OCC(X_train, X_test_n, X_test_a)\n","        auc = AUC_OC(n_mse, a_mse)\n","        print(\"\\nFor the class: \", one_class)\n","        print(\"\\nAUC: \", auc)\n","      else:\n","        # do for the chosen \n","        for gamma in np.logspace(-10, 1, num=10, base=2):\n","            n_mse, a_mse = kernelpca_OCC(X, y, split_percentage, one_class, gamma=gamma)\n","            new_auc = AUC_OC(n_mse, a_mse)\n","            print(\"\\nFor the class: \", one_class)\n","            print(\"\\n gamma: \", gamma)\n","            print(\"\\nAUC: \", new_auc)\n","            if new_auc > best_auc :\n","              best_auc = new_auc\n","              optimum_gamma = gamma\n","        print(\"=====================\")\n","        print(\"\\nFor the class: \", one_class)\n","        print(\"\\nOptimum gamma: \", optimum_gamma)\n","        print(\"\\nBest AUC: \", best_auc)\n","        print(\"=====================\")"]},{"cell_type":"code","execution_count":null,"id":"5cb63e5c","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b1be9727","metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}
